# ETL NotÃ­cias Agro - Sistema de CotaÃ§Ãµes

Sistema otimizado para coleta e armazenamento de dados de cotaÃ§Ãµes de boi gordo do portal NotÃ­cias AgrÃ­colas.

## ğŸš€ CaracterÃ­sticas

- **Coleta automatizada** de cotaÃ§Ãµes diÃ¡rias
- **Armazenamento eficiente** em formato Parquet
- **Particionamento inteligente** por ano/mÃªs
- **Processamento paralelo** para grandes volumes
- **Schema padronizado** para diferentes tipos de dados
- **Consultas otimizadas** para anÃ¡lise de dados
- **Suporte a mÃºltiplas datas** com backfill automÃ¡tico

## ğŸ“ Estrutura do Projeto

```
ETL_NoticiasAgro/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper.py           # Coleta de dados do site
â”‚   â”œâ”€â”€ data_processor.py    # Processamento e armazenamento
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ output/
â”‚   â””â”€â”€ parquet/            # Dados em formato Parquet
â”‚       â”œâ”€â”€ indicadores_simples/
â”‚       â”œâ”€â”€ indicadores_estados/
â”‚       â”œâ”€â”€ contratos_futuros/
â”‚       â”œâ”€â”€ reposicao/
â”‚       â””â”€â”€ mercados_externos/
â”œâ”€â”€ main.py                 # Script principal CLI
â”œâ”€â”€ examples.py            # Exemplos de uso
â”œâ”€â”€ requirements.txt       # DependÃªncias
â””â”€â”€ README.md             # Este arquivo
```

## ğŸ› ï¸ InstalaÃ§Ã£o

1. **Criar ambiente virtual**:
   ```bash
   python -m venv .venv
   .venv\Scripts\Activate  # Windows
   # source .venv/bin/activate  # Linux/Mac
   ```

2. **Instalar dependÃªncias**:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ“Š Tipos de Dados Coletados

O sistema organiza automaticamente os dados em 5 categorias:

### 1. **Indicadores Simples** (`indicadores_simples`)
- Indicador do Boi Gordo Esalq/B3
- Boi Gordo - MÃ©dia SP a prazo
- Bezerro Esalq/BM&F Bovespa - MS

**Schema**: `date`, `indicator_name`, `price_brl`, `variation_pct`, `price_usd`

### 2. **Indicadores por Estado** (`indicadores_estados`)
- Indicador da Novilha
- Indicador da Vaca  
- Indicador do Boi
- MÃ©dia de Boi Gordo - Indicador AgroBrazil

**Schema**: `date`, `indicator_name`, `state`, `price_brl`, `variation_pct`, `price_usd`

### 3. **Contratos Futuros** (`contratos_futuros`)
- Boi Gordo - B3 (PregÃ£o Regular)

**Schema**: `date`, `contract_month`, `price`, `variation`, `indicator_name`

### 4. **ReposiÃ§Ã£o** (`reposicao`)
- ReposiÃ§Ã£o Nelore - FÃªmea
- ReposiÃ§Ã£o Nelore - Macho

**Schema**: `date`, `state`, `category`, `desmama`, `bezerra_bezerro`, `novilha_garrote`, `vaca_boi_magro`, `indicator_name`

### 5. **Mercados Externos** (`mercados_externos`)
- Chicago (CME)
- Brasil (B3)
- New York (NYBOT)

**Schema**: `date`, `market`, `contract`, `price`, `variation`

## ğŸ”§ Uso do Sistema

### Comando Principal (main.py)

#### Coletar uma data especÃ­fica:
```bash
python main.py single --date 2025-08-20
```

#### Coletar um intervalo de datas:
```bash
python main.py range --start-date 2025-08-01 --end-date 2025-08-20
```

#### Backfill automÃ¡tico (Ãºltimos 30 dias):
```bash
python main.py backfill
```

#### Backfill personalizado:
```bash
python main.py backfill --start-date 2024-01-01 --end-date 2025-08-27
```

#### Ver estatÃ­sticas de armazenamento:
```bash
python main.py stats
```

#### OpÃ§Ãµes adicionais:
```bash
# Usar mais workers para processamento paralelo
python main.py range --start-date 2025-08-01 --end-date 2025-08-20 --workers 5

# Reprocessar arquivos existentes
python main.py range --start-date 2025-08-01 --end-date 2025-08-20 --force

# DiretÃ³rio de saÃ­da personalizado
python main.py single --date 2025-08-20 --output-dir /path/to/custom/output
```

### Uso ProgramÃ¡tico

```python
from src.scraper import scrap_ox_data
from src.data_processor import CotacaoDataProcessor

# Coletar dados de uma data
raw_data = scrap_ox_data("2025-08-20")

# Processar e salvar
processor = CotacaoDataProcessor("output")
processed_dfs = processor.process_raw_data(raw_data)
processor.save_to_parquet(processed_dfs, "2025-08-20")

# Consultar dados armazenados
data = processor.load_date_range("2025-08-01", "2025-08-20", ["indicadores_estados"])
df_estados = data["indicadores_estados"]
print(f"Dados carregados: {len(df_estados)} registros")
```

## ğŸ“ˆ AnÃ¡lise de Dados

### Exemplos de Consultas

```python
import pandas as pd
from src.data_processor import CotacaoDataProcessor

processor = CotacaoDataProcessor("output")

# Carregar dados de indicadores por estado
data = processor.load_date_range("2025-08-01", "2025-08-20", ["indicadores_estados"])
df = data["indicadores_estados"]

# PreÃ§o mÃ©dio por estado
precos_por_estado = df.groupby('state')['price_brl'].mean().sort_values(ascending=False)
print(precos_por_estado)

# VariaÃ§Ã£o diÃ¡ria de preÃ§os
variacao_diaria = df.groupby('date')['price_brl'].mean()
print(variacao_diaria)

# Top 5 estados com maior preÃ§o
top_estados = df.groupby('state')['price_brl'].mean().nlargest(5)
print(top_estados)
```

### ExportaÃ§Ã£o

```python
# Exportar para CSV
df.to_csv("cotacoes_estados.csv", index=False, encoding='utf-8')

# Exportar para Excel
df.to_excel("cotacoes_estados.xlsx", index=False)

# Criar resumo por estado
resumo = df.groupby(['state', 'date']).agg({
    'price_brl': ['mean', 'min', 'max'],
    'variation_pct': 'mean'
}).round(2)
resumo.to_csv("resumo_cotacoes.csv")
```

## ğŸ¯ Vantagens do Sistema

### **1. Armazenamento Eficiente**
- **Formato Parquet**: CompressÃ£o atÃ© 80% menor que CSV
- **Particionamento**: Consultas rÃ¡pidas por perÃ­odo
- **Schema tipado**: ValidaÃ§Ã£o automÃ¡tica de dados

### **2. Escalabilidade**
- **Processamento paralelo**: MÃºltiplas datas simultÃ¢neas
- **Incremental**: Processa apenas datas novas
- **Particionamento**: Suporta dÃ©cadas de dados

### **3. AnÃ¡lise Otimizada**
- **Consultas rÃ¡pidas**: Por data, estado ou indicador
- **AgregaÃ§Ãµes eficientes**: GroupBy otimizado
- **IntegraÃ§Ã£o**: Pandas, Jupyter, BI tools

### **4. Robustez**
- **Retry automÃ¡tico**: Em caso de falhas de rede
- **Logs detalhados**: Para monitoramento
- **ValidaÃ§Ã£o**: Schema consistente

## ğŸ“Š Performance Estimada

Para **10 anos de dados diÃ¡rios**:

| MÃ©trica | Estimativa |
|---------|-----------|
| Total de arquivos | ~18.250 arquivos |
| Tamanho aproximado | ~2-5 GB |
| Consulta 1 ano | < 2 segundos |
| Coleta 1 dia | 3-5 segundos |
| Processamento paralelo | 100 dias/minuto |

## ğŸ” Monitoramento

### Ver estatÃ­sticas:
```bash
python main.py stats
```

### Verificar logs:
```bash
cat output/etl_logs.txt
```

### Estrutura de arquivos:
```
output/parquet/
â”œâ”€â”€ indicadores_estados/
â”‚   â”œâ”€â”€ 2024/
â”‚   â”‚   â”œâ”€â”€ 01/cotacoes_2024-01-15.parquet
â”‚   â”‚   â”œâ”€â”€ 02/cotacoes_2024-02-10.parquet
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ 2025/
â”‚       â”œâ”€â”€ 08/cotacoes_2025-08-20.parquet
â”‚       â””â”€â”€ ...
â””â”€â”€ ...
```

## ğŸ”„ AutomaÃ§Ã£o

### Crontab (Linux/Mac):
```bash
# Coleta diÃ¡ria Ã s 18h
0 18 * * * cd /path/to/project && python main.py single --date $(date +%Y-%m-%d)

# Backfill semanal aos domingos
0 2 * * 0 cd /path/to/project && python main.py backfill
```

### Task Scheduler (Windows):
```powershell
# Criar tarefa diÃ¡ria
schtasks /create /tn "Cotacoes_Diaria" /tr "python main.py single --date $(Get-Date -f 'yyyy-MM-dd')" /sc daily /st 18:00
```

## ğŸš¨ Troubleshooting

### **Erro de rede**
```python
# Dados nÃ£o encontrados ou erro 404
# Verificar se a data Ã© um dia Ãºtil (sem fins de semana/feriados)
```

### **Problema de dependÃªncias**
```bash
# Reinstalar dependÃªncias
pip uninstall -r requirements.txt -y
pip install -r requirements.txt
```

### **Arquivos corrompidos**
```bash
# Reprocessar com --force
python main.py single --date 2025-08-20 --force
```

## ğŸ“ Suporte

Para dÃºvidas ou problemas:
1. Verificar logs em `output/etl_logs.txt`
2. Executar `python examples.py` para teste
3. Verificar se o site estÃ¡ acessÃ­vel
4. Validar formato de datas (YYYY-MM-DD)

---

**Nota**: Este sistema foi desenvolvido para fins educacionais e de pesquisa. Respeite os termos de uso do site NotÃ­cias AgrÃ­colas e implemente delays adequados entre requisiÃ§Ãµes.
